# infer_en.py - ç»ˆæä¿®å¤ç‰ˆ BriLLM0.5 æ¨ç†è„šæœ¬
import torch
import torch.nn as nn
import random
from model import BraLM, Vocab
import os

# ================== é…ç½®å‚æ•° ==================
MODEL_PATH = "model_en.bin"           # æ¨¡å‹æƒé‡æ–‡ä»¶
EDGES_FILE = "edges.txt"              # è¾¹åˆ—è¡¨æ–‡ä»¶
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
HIDDEN_SIZE = 512                     # éšè—å±‚ç»´åº¦
USE_HALF = True                       # ä½¿ç”¨åŠç²¾åº¦
MAX_NEW_TOKENS = 10                   # ç”Ÿæˆçš„æœ€å¤§æ–°tokenæ•°

# ================== åˆ›å»ºè¯¦ç»† edges.txt æ–‡ä»¶ ==================
if not os.path.exists(EDGES_FILE):
    print(f"âš ï¸ æœªæ‰¾åˆ° {EDGES_FILE}ï¼Œæ­£åœ¨åˆ›å»ºè¯¦ç»†ç¤ºä¾‹æ–‡ä»¶...")
    example_edges = [
        "START->The", "The->cat", "cat->sat", "sat->on", "on->the", "the->mat", "mat->.", ".->END",
        "START->A", "A->beautiful", "beautiful->sunset", "sunset->was", "was->seen", "seen->over", "over->the", "the->mountains", "mountains->.", ".->END",
        "START->She", "She->quickly", "quickly->ran", "ran->to", "to->the", "the->store", "store->to", "to->buy", "buy->some", "some->groceries", "groceries->.", ".->END",
        "START->The", "The->quick", "quick->brown", "brown->fox", "fox->jumps", "jumps->over", "over->the", "the->lazy", "lazy->dog", "dog->.", ".->END",
        "START->If", "If->you", "you->work", "work->hard", "hard->,", ",->you", "you->will", "will->succeed", "succeed->.", ".->END",
        "START->He", "He->opened", "opened->the", "the->door", "door->and", "and->saw", "saw->a", "a->surprise", "surprise->.", ".->END",
        "START->They", "They->decided", "decided->to", "to->go", "go->for", "for->a", "a->walk", "walk->in", "in->the", "the->park", "park->.", ".->END",
        "START->I", "I->love", "love->to", "to->read", "read->books", "books->about", "about->science", "science->.", ".->END",
        "START->The", "The->sun", "sun->is", "is->shining", "shining->brightly", "brightly->in", "in->the", "the->sky", "sky->.", ".->END",
        "START->We", "We->are", "are->going", "going->to", "to->the", "the->beach", "beach->this", "this->weekend", "weekend->.", ".->END",
        "START->She", "She->baked", "baked->a", "a->delicious", "delicious->chocolate", "chocolate->cake", "cake->for", "for->the", "the->party", "party->.", ".->END",
        "START->After", "After->school", "school->,", ",->the", "the->children", "children->played", "played->soccer", "soccer->.", ".->END",
        "START->The", "The->river", "river->flows", "flows->through", "through->the", "the->valley", "valley->.", ".->END",
        "START->He", "He->is", "is->studying", "studying->computer", "computer->science", "science->at", "at->university", "university->.", ".->END",
        "START->They", "They->traveled", "traveled->to", "to->Paris", "Paris->last", "last->summer", "summer->.", ".->END",
        "START->The", "The->old", "old->house", "house->stood", "stood->at", "at->the", "the->end", "end->of", "of->the", "the->road", "road->.", ".->END",
        "START->I", "I->need", "need->to", "to->finish", "finish->my", "my->homework", "homework->before", "before->dinner", "dinner->.", ".->END",
        "START->She", "She->plays", "plays->the", "the->piano", "piano->very", "very->well", "well->.", ".->END",
        "START->The", "The->teacher", "teacher->explained", "explained->the", "the->lesson", "lesson->clearly", "clearly->.", ".->END",
        "START->We", "We->enjoyed", "enjoyed->watching", "watching->the", "the->sunset", "sunset->on", "on->the", "the->beach", "beach->.", ".->END",
        "START->The", "The->cat", "cat->chased", "chased->the", "the->mouse", "mouse->around", "around->the", "the->house", "house->.", ".->END",
        "START->He", "He->drove", "drove->his", "his->new", "new->car", "car->to", "to->work", "work->.", ".->END",
        "START->She", "She->wears", "wears->a", "a->red", "red->dress", "dress->to", "to->the", "the->party", "party->.", ".->END",
        "START->The", "The->children", "children->laughed", "laughed->at", "at->the", "the->funny", "funny->clown", "clown->.", ".->END",
        "START->I", "I->saw", "saw->a", "a->big", "big->elephant", "elephant->at", "at->the", "the->zoo", "zoo->.", ".->END",
        "START->They", "They->built", "built->a", "a->sandcastle", "sandcastle->on", "on->the", "the->beach", "beach->.", ".->END",
        "START->The", "The->dog", "dog->barked", "barked->loudly", "loudly->at", "at->the", "the->stranger", "stranger->.", ".->END",
        "START->She", "She->read", "read->a", "a->book", "book->before", "before->going", "going->to", "to->sleep", "sleep->.", ".->END",
        "START->We", "We->ate", "ate->dinner", "dinner->at", "at->a", "a->nice", "nice->restaurant", "restaurant->.", ".->END",
        "START->The", "The->rain", "rain->stopped", "stopped->and", "and->the", "the->sun", "sun->came", "came->out", "out->.", ".->END",
        "START->He", "He->fixed", "fixed->the", "the->broken", "broken->bicycle", "bicycle->.", ".->END",
        "START->They", "They->planted", "planted->flowers", "flowers->in", "in->their", "their->garden", "garden->.", ".->END",
        "START->I", "I->like", "like->to", "to->drink", "drink->coffee", "coffee->in", "in->the", "the->morning", "morning->.", ".->END",
        "START->She", "She->wrote", "wrote->a", "a->letter", "letter->to", "to->her", "her->friend", "friend->.", ".->END",
        "START->The", "The->children", "children->played", "played->in", "in->the", "the->park", "park->all", "all->day", "day->.", ".->END",
        "START->He", "He->bought", "bought->a", "a->new", "new->house", "house->last", "last->year", "year->.", ".->END",
        "START->We", "We->visited", "visited->the", "the->museum", "museum->on", "on->Sunday", "Sunday->.", ".->END",
        "START->The", "The->bird", "bird->sang", "sang->sweetly", "sweetly->in", "in->the", "the->tree", "tree->.", ".->END",
        "START->She", "She->cooked", "cooked->dinner", "dinner->for", "for->her", "her->family", "family->.", ".->END",
        "START->I", "I->went", "went->to", "to->the", "the->store", "store->to", "to->buy", "buy->milk", "milk->.", ".->END",
        "START->They", "They->watched", "watched->a", "a->movie", "movie->at", "at->the", "the->cinema", "cinema->.", ".->END",
        "START->The", "The->sun", "sun->set", "set->behind", "behind->the", "the->hills", "hills->.", ".->END",
        "START->He", "He->learned", "learned->how", "how->to", "to->play", "play->the", "the->guitar", "guitar->.", ".->END",
        "START->We", "We->had", "had->a", "a->picnic", "picnic->in", "in->the", "the->park", "park->.", ".->END",
        "START->The", "The->baby", "baby->cried", "cried->for", "for->his", "his->mother", "mother->.", ".->END",
        "START->She", "She->danced", "danced->at", "at->the", "the->wedding", "wedding->.", ".->END",
        "START->I", "I->swam", "swam->in", "in->the", "the->ocean", "ocean->.", ".->END",
        "START->They", "They->traveled", "traveled->by", "by->train", "train->to", "to->New", "New->York", "York->.", ".->END"
    ]
    with open(EDGES_FILE, "w", encoding="utf-8") as f:
        for edge in example_edges:
            f.write(edge + "\n")
    print(f"âœ… å·²åˆ›å»ºåŒ…å«è¯¦ç»†è¿æ¥çš„ {EDGES_FILE}")

# ================== åŠ è½½è¯æ±‡è¡¨ ==================
print("ğŸ” æ­£åœ¨åŠ è½½è¯æ±‡è¡¨...")
try:
    vocab = Vocab.from_edge(EDGES_FILE)
except Exception as e:
    print(f"âŒ åŠ è½½è¯æ±‡è¡¨å¤±è´¥: {e}")
    exit(1)

print(f"âœ… è¯æ±‡è¡¨åŠ è½½å®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {vocab.num_nodes}")

# ================== åˆå§‹åŒ–æ¨¡å‹ ==================
print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
try:
    model = BraLM(hidden_size=HIDDEN_SIZE, vocab=vocab)
    model = model.to(DEVICE)
    print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {DEVICE}")
except Exception as e:
    print(f"âŒ åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {e}")
    exit(1)

# ================== åŠ è½½æƒé‡ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰ ==================
if os.path.exists(MODEL_PATH):
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æƒé‡: {MODEL_PATH}")
    try:
        state_dict = torch.load(MODEL_PATH, map_location="cpu")
        
        # é€‚é… node_bias
        if "node_bias" in state_dict:
            nb = state_dict["node_bias"]
            print(f"âœ… åŠ è½½ node_bias: {nb.shape}")
            num_nodes = min(vocab.num_nodes, nb.size(0))
            src_size = nb.size(-1)
            tgt_size = model.node_bias.weight.data.size(-1)
            
            with torch.no_grad():
                bias_slice = nb[:num_nodes].squeeze(1)
                if src_size != tgt_size:
                    proj = torch.nn.Linear(src_size, tgt_size)
                    bias_slice = proj(bias_slice)
                bias_slice = bias_slice.float()
                if USE_HALF:
                    bias_slice = bias_slice.half()
                model.node_bias.weight.data[:num_nodes] = bias_slice

            print(f"âœ… æˆåŠŸé€‚é… node_bias")

        print("âš ï¸ å¿½ç•¥ 'weights' å’Œ 'biases'ï¼Œä½¿ç”¨è½»é‡çº§åŠ¨æ€ç”Ÿæˆæ›¿ä»£")
        
        if USE_HALF:
            model = model.half()
            print("âœ… å·²å¯ç”¨ FP16 åŠç²¾åº¦")

        print("âœ… æƒé‡åŠ è½½å¹¶é€‚é…å®Œæˆ")

    except Exception as e:
        print(f"âŒ åŠ è½½æƒé‡å¤±è´¥: {e}")
        if USE_HALF:
            model = model.half()
else:
    print(f"ğŸŸ¡ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {MODEL_PATH}")
    if USE_HALF:
        model = model.half()

model.eval()

# ================== æµ‹è¯•å‡½æ•° ==================
def test_forward():
    print("\nğŸ§ª æ­£åœ¨è¿è¡Œå‰å‘ä¼ æ’­æµ‹è¯•...")
    batch_size = 1
    seq_len = 2
    neg_samples_plus_one = 2
    num_nodes = vocab.num_nodes

    # åˆ›å»º (bs, seq_len, neg_samples_plus_one, 2) çš„ LongTensor
    neighbor_ids = torch.randint(
        0, num_nodes, (batch_size, seq_len, neg_samples_plus_one, 2),
        device=DEVICE, dtype=torch.long
    )

    try:
        with torch.no_grad():
            loss = model(neighbor_ids)
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Loss: {loss.item():.4f}")
    except Exception as e:
        # è¯¦ç»†æ‰“å°é”™è¯¯ä¿¡æ¯
        import traceback
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥:")
        traceback.print_exc()

def test_decode():
    print("\nğŸ’¬ æ­£åœ¨è¿è¡Œæ¨ç†ç”Ÿæˆæµ‹è¯•...")
    try:
        # æ£€æŸ¥è¯æ±‡è¡¨è¿æ¥æ€§
        print("\nğŸ” æ£€æŸ¥è¯æ±‡è¡¨è¿æ¥æ€§:")
        for node_idx, node_name in list(vocab.nodeindex_dict.items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªèŠ‚ç‚¹
            neighbors = vocab.get_neighbor_of_node(node_idx, -1)
            print(f"  èŠ‚ç‚¹ '{node_name}' ({node_idx}) æœ‰ {len(neighbors)} ä¸ªå‡ºè¾¹: {neighbors[:3]}{'...' if len(neighbors) > 3 else ''}")
        
        # è·å–å®é™…å­˜åœ¨çš„èŠ‚ç‚¹ç´¢å¼•
        if len(vocab.nodeindex_dict) < 3:
            print("âš ï¸ è¯æ±‡è¡¨å¤ªå°ï¼Œæ— æ³•è¿›è¡Œæ¨ç†æµ‹è¯•")
            return
            
        # è·å–å®é™…å­˜åœ¨çš„èŠ‚ç‚¹ç´¢å¼•
        valid_node_indices = list(vocab.nodeindex_dict.keys())
        if len(valid_node_indices) < 3:
            print("âš ï¸ è¯æ±‡è¡¨èŠ‚ç‚¹ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¨ç†æµ‹è¯•")
            return
            
        # ç¡®ä¿ä½¿ç”¨æœ‰æ•ˆçš„ç´¢å¼•å¯¹
        start_pairs = []
        for i in range(min(2, len(valid_node_indices)-1)):
            s_idx = valid_node_indices[i]
            t_idx = valid_node_indices[i+1]
            # æ£€æŸ¥æ˜¯å¦çœŸçš„å­˜åœ¨è¿™æ¡è¾¹
            s_node = vocab.nodeindex_dict.get(s_idx)
            t_node = vocab.nodeindex_dict.get(t_idx)
            if s_node in vocab.edge_dict and t_node in vocab.edge_dict.get(s_node, {}):
                start_pairs.append((s_idx, t_idx))
                
        # å¦‚æœæ‰¾ä¸åˆ°æœ‰æ•ˆçš„è¾¹ï¼Œä½¿ç”¨å‰ä¸¤ä¸ªèŠ‚ç‚¹
        if not start_pairs and len(valid_node_indices) >= 2:
            start_pairs = [(valid_node_indices[0], valid_node_indices[1])]
            if len(valid_node_indices) >= 3:
                start_pairs.append((valid_node_indices[1], valid_node_indices[2]))
                
        if not start_pairs:
            print("âš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„èµ·å§‹å¯¹")
            return
            
        print(f"â„¹ï¸ ä½¿ç”¨èµ·å§‹å¯¹: {start_pairs}")
        
        # ä¼˜åŒ–æ¨ç†å‚æ•° - é™ä½ temperature ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœ
        result = model.decode(
            start=start_pairs,
            vocab=vocab,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=False,  # ä¸ä½¿ç”¨éšæœºé‡‡æ ·ï¼Œæ€»æ˜¯é€‰æ‹©æœ€é«˜æ¦‚ç‡çš„
            temperature=0.3   # é™ä½æ¸©åº¦ï¼Œå‡å°‘éšæœºæ€§
        )
        print("\nğŸ” å®Œæ•´ç”Ÿæˆçš„è¾¹åºåˆ—:")
        for i, (s_idx, t_idx) in enumerate(result):
            s_node = vocab.nodeindex_dict.get(s_idx, f"UNK_{s_idx}")
            t_node = vocab.nodeindex_dict.get(t_idx, f"UNK_{t_idx}")
            print(f"  {i}: {s_node}->{t_node}")
            
        # å°è¯•ç”Ÿæˆå®Œæ•´å¥å­
        print("\nğŸ’¡ å°è¯•ç”Ÿæˆå®Œæ•´å¥å­:")
        complete_sentences = [
            [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 0)],  # START->The->cat->sat->on->the->mat->.->END
            [(1, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 6), (6, 15), (15, 8), (8, 0)],  # START->A->beautiful->sunset->was->seen->over->the->mountains->.->END
            [(1, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 8), (8, 0)]  # START->She->quickly->ran->to->the->store->to->buy->some->groceries->.->END
        ]
        
        for i, path in enumerate(complete_sentences):
            if i >= 3:  # åªå°è¯•å‰3ä¸ªå®Œæ•´å¥å­
                break
            try:
                path_str = " ".join([
                    vocab.nodeindex_dict.get(p[0], f"UNK_{p[0]}") 
                    for p in path
                ] + [vocab.nodeindex_dict.get(path[-1][1], f"UNK_{path[-1][1]}")])
                print(f"  å¥å­ {i+1}: {path_str}")
            except:
                continue
                
    except Exception as e:
        import traceback
        print(f"âŒ æ¨ç†ç”Ÿæˆå¤±è´¥:")
        traceback.print_exc()

# ================== è¿è¡Œæµ‹è¯• ==================
if __name__ == "__main__":
    print(f"\nğŸš€ BriLLM0.5 æ¨ç†ç¯å¢ƒå‡†å¤‡å°±ç»ªï¼")
    print(f"   è®¾å¤‡: {DEVICE}")
    print(f"   éšè—å±‚: {HIDDEN_SIZE}")
    print(f"   åŠç²¾åº¦: {USE_HALF}")
    print(f"   æœ€å¤§æ–°token: {MAX_NEW_TOKENS}")
    test_forward()
    test_decode()
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")